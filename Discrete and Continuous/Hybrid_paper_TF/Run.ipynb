{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from Distillation_disc_cont import Simulator\n",
    "from memory import Memory\n",
    "from Actor_Critic import Agent\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.load_session('Agent.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make agent and define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "beta = 1e-4 \n",
    "gamma = 0.97\n",
    "\n",
    "num_episodes = int(1e4)\n",
    "memory_size = int(1e5)\n",
    "batch_size = 50\n",
    "pretrain_eps = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 30)           210         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 30)           930         fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 30)           930         fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "policy_output (Dense)           (None, 1)            31          fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "discrete_action_output (Dense)  (None, 5)            155         fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "policy_output_actual_value (Lam (None, 1)            0           policy_output[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,256\n",
      "Trainable params: 2,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = Simulator()\n",
    "memory = Memory(max_size = memory_size)\n",
    "agent = Agent(env = env, alpha = alpha, beta = beta, gamma = gamma, layer_size = 30)\n",
    "agent.actor.summary()\n",
    "#agent.critic.summary()\n",
    "#agent.policy.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the experience memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "\n",
    "for ep in range(pretrain_eps):\n",
    "    action = env.discrete_action_space.sample(), env.continuous_action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    if done:\n",
    "        next_state = np.zeros(env.observation_space.shape)\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "    else:\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, avg_score -1542.138485995535, last action (4, array([[-0.24012441]]))\n",
      "episode 100, avg_score -1297.2067442069235, last action (2, array([[-0.16284093]]))\n",
      "episode 200, avg_score -1097.659805671419, last action (2, array([[0.91274206]]))\n",
      "episode 300, avg_score -938.0143255154842, last action (2, array([[0.39179336]]))\n",
      "episode 400, avg_score -936.9526623297731, last action (2, array([[-0.24977556]]))\n",
      "episode 500, avg_score -981.0626216239142, last action (2, array([[0.37308161]]))\n",
      "episode 600, avg_score -991.7988878604154, last action (2, array([[-1.99877446]]))\n",
      "episode 700, avg_score -987.6207589727519, last action (2, array([[-0.79934632]]))\n",
      "episode 800, avg_score -1014.8524077585888, last action (2, array([[0.54244856]]))\n",
      "episode 900, avg_score -1061.6322141325904, last action (2, array([[0.53378868]]))\n",
      "episode 1000, avg_score -1119.0559107840586, last action (2, array([[0.62090463]]))\n",
      "episode 1100, avg_score -1081.627083632507, last action (2, array([[-0.06567571]]))\n",
      "episode 1200, avg_score -1129.4242906160289, last action (2, array([[0.98060149]]))\n",
      "episode 1300, avg_score -998.8151833636703, last action (2, array([[0.37713247]]))\n",
      "episode 1400, avg_score -1059.7519232289546, last action (2, array([[0.03493393]]))\n",
      "episode 1500, avg_score -1210.3987555799954, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 1600, avg_score -1209.9137034299654, last action (2, array([[0.46373153]]))\n",
      "episode 1700, avg_score -1140.9844605538208, last action (2, array([[-0.02974008]]))\n",
      "episode 1800, avg_score -1170.6910002664272, last action (2, array([[-0.40421648]]))\n",
      "episode 1900, avg_score -1156.7813447686165, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 2000, avg_score -67.25420232078936, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 2100, avg_score -1240.158461728988, last action (2, array([[0.89691735]]))\n",
      "episode 2200, avg_score -1212.7678328376821, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 2300, avg_score -1217.561089386461, last action (3, array([[-0.14572261]]))\n",
      "episode 2400, avg_score -1253.8660882282811, last action (2, array([[0.70186311]]))\n",
      "episode 2500, avg_score -1211.702444164973, last action (2, array([[-0.05420544]]))\n",
      "episode 2600, avg_score -1193.4524108014557, last action (2, array([[0.57295433]]))\n",
      "episode 2700, avg_score -1255.9464976342438, last action (2, array([[0.93421394]]))\n",
      "episode 2800, avg_score -1278.104035536241, last action (2, array([[0.66433201]]))\n",
      "episode 2900, avg_score -1315.2432876516439, last action (2, array([[0.58759262]]))\n",
      "episode 3000, avg_score -1256.0228983417026, last action (2, array([[-0.16200621]]))\n",
      "episode 3100, avg_score -1275.4007224092288, last action (1, array([[-0.21573126]]))\n",
      "episode 3200, avg_score -1362.1859512097665, last action (2, array([[0.23417567]]))\n",
      "episode 3300, avg_score -1234.0379870793256, last action (2, array([[0.91711175]]))\n",
      "episode 3400, avg_score -1194.480396376848, last action (2, array([[0.16718845]]))\n",
      "episode 3500, avg_score -1310.1740726113164, last action (2, array([[0.07798495]]))\n",
      "episode 3600, avg_score -1312.2212582670481, last action (2, array([[0.66168226]]))\n",
      "episode 3700, avg_score -1387.697715624844, last action (0, array([[-0.26870098]]))\n",
      "episode 3800, avg_score -1326.8382403309004, last action (2, array([[0.15206517]]))\n",
      "episode 3900, avg_score -1352.6579528221241, last action (3, array([[0.47391463]]))\n",
      "episode 4000, avg_score -1343.0550572723266, last action (2, array([[0.6789538]]))\n",
      "episode 4100, avg_score -1367.3024593712908, last action (2, array([[0.85359467]]))\n",
      "episode 4200, avg_score -1334.1783597901021, last action (2, array([[0.61498851]]))\n",
      "episode 4300, avg_score -1447.656137878752, last action (2, array([[0.82131906]]))\n",
      "episode 4400, avg_score -1373.834495409009, last action (2, array([[0.43616574]]))\n",
      "episode 4500, avg_score -1425.5845725444367, last action (2, array([[0.1901453]]))\n",
      "episode 4600, avg_score -1456.7238819185977, last action (2, array([[0.23724998]]))\n",
      "episode 4700, avg_score -1383.6918059921, last action (2, array([[0.62063032]]))\n",
      "episode 4800, avg_score -1403.7066949745242, last action (4, array([[0.12329863]]))\n",
      "episode 4900, avg_score -1481.3778830640626, last action (0, array([[0.45002934]]))\n",
      "episode 5000, avg_score -1438.5534399285273, last action (0, array([[0.92836199]]))\n",
      "episode 5100, avg_score -1510.6243216218345, last action (2, array([[-0.17567309]]))\n",
      "episode 5200, avg_score -1465.4965176844541, last action (2, array([[0.2038906]]))\n",
      "episode 5300, avg_score -1427.8090929689226, last action (2, array([[0.60280871]]))\n",
      "episode 5400, avg_score -1489.456650688003, last action (2, array([[0.67618952]]))\n",
      "episode 5500, avg_score -1525.5131740754962, last action (2, array([[0.52266675]]))\n",
      "episode 5600, avg_score -1488.497255852377, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 5700, avg_score -1455.1747145247612, last action (2, array([[0.54895253]]))\n",
      "episode 5800, avg_score -1547.1060436051894, last action (2, array([[0.75080249]]))\n",
      "episode 5900, avg_score -1500.1218826495844, last action (1, array([[0.1849366]]))\n",
      "episode 6000, avg_score -1470.9134401068443, last action (2, array([[0.02681136]]))\n",
      "episode 6100, avg_score -1487.1483882877565, last action (2, array([[0.18089014]]))\n",
      "episode 6200, avg_score -1538.4622619767545, last action (4, array([[0.89175387]]))\n",
      "episode 6300, avg_score -1519.8467303537373, last action (2, array([[0.45101003]]))\n",
      "episode 6400, avg_score -1521.8253624793495, last action (3, array([[0.39973701]]))\n",
      "episode 6500, avg_score -1515.3556727625435, last action (1, array([[0.91092779]]))\n",
      "episode 6600, avg_score -1543.5440524420046, last action (4, array([[0.90454421]]))\n",
      "episode 6700, avg_score -1560.3845933264188, last action (2, array([[0.52395066]]))\n",
      "episode 6800, avg_score -1507.3031312147411, last action (1, array([[0.62689885]]))\n",
      "episode 6900, avg_score -1493.6697430720417, last action (4, array([[0.18090207]]))\n",
      "episode 7000, avg_score -1528.216542438, last action (0, array([[0.35317987]]))\n",
      "episode 7100, avg_score -1540.0038180738068, last action (2, array([[0.71075366]]))\n",
      "episode 7200, avg_score -1523.1308836376352, last action (4, array([[0.81314857]]))\n",
      "episode 7300, avg_score -1543.3150914027342, last action (2, array([[0.23191816]]))\n",
      "episode 7400, avg_score -1520.0633366438215, last action (3, array([[0.42065981]]))\n",
      "episode 7500, avg_score -1565.8932440030756, last action (2, array([[0.46904969]]))\n",
      "episode 7600, avg_score -1596.489747731647, last action (2, array([[0.4795663]]))\n",
      "episode 7700, avg_score -1563.2791874558197, last action (2, array([[0.33160917]]))\n",
      "episode 7800, avg_score -1552.5946192865924, last action (4, array([[0.53700604]]))\n",
      "episode 7900, avg_score -1546.2824682937703, last action (1, array([[0.49139626]]))\n",
      "episode 8000, avg_score -1580.6227471524287, last action (2, array([[0.19379694]]))\n",
      "episode 8100, avg_score -1544.6897465346578, last action (1, array([[0.43975625]]))\n",
      "episode 8200, avg_score -1564.7917116484862, last action (3, array([[0.54537072]]))\n",
      "episode 8300, avg_score -1544.5346126658408, last action (1, array([[0.31944495]]))\n",
      "episode 8400, avg_score -1609.5194413866482, last action (3, array([[0.64247473]]))\n",
      "episode 8500, avg_score -1587.408361061174, last action (4, array([[0.55191675]]))\n",
      "episode 8600, avg_score -1519.5733278230475, last action (2, array([[0.63112291]]))\n",
      "episode 8700, avg_score -1607.6004139288236, last action (3, array([[0.51774542]]))\n",
      "episode 8800, avg_score -1602.2634359307713, last action (4, array([[0.50215061]]))\n",
      "episode 8900, avg_score -1547.2577108817145, last action (1, array([[0.36175237]]))\n",
      "episode 9000, avg_score -1528.9981507691828, last action (2, array([[0.66216887]]))\n",
      "episode 9100, avg_score -1543.4601203737207, last action (3, array([[0.54737829]]))\n",
      "episode 9200, avg_score -1557.1879947232817, last action (1, array([[0.54044133]]))\n",
      "episode 9300, avg_score -1525.0532517145894, last action (0, array([[0.55830576]]))\n",
      "episode 9400, avg_score -1570.5307396177907, last action (0, array([[0.48305198]]))\n",
      "episode 9500, avg_score -1567.4046826207878, last action (2, array([[0.50307163]]))\n",
      "episode 9600, avg_score -1552.8831014579887, last action (0, array([[0.49954437]]))\n",
      "episode 9700, avg_score -1511.905205418224, last action (4, array([[0.55773151]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9800, avg_score -1574.4521313639082, last action (1, array([[0.49400965]]))\n",
      "episode 9900, avg_score -1573.3706846853227, last action (2, array([[0.50070384]]))\n"
     ]
    }
   ],
   "source": [
    "score_history = []\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.choose_action_epsgreedy(state, i, num_episodes)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        #agent.learn(state,  action, reward, next_state, done)\n",
    "        score += reward\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "    \n",
    "    score_history.append(score)\n",
    "    next_state = np.zeros(state.shape)\n",
    "    memory.add((state, action, reward, next_state))\n",
    "    \n",
    "    avg_score = np.mean(score_history[-100:]) #average of last 100 scores\n",
    "    if i%100 == 0:\n",
    "        print(f'episode {i}, avg_score {avg_score}, last action {action}')\n",
    "        \n",
    "    batch = memory.sample(batch_size)\n",
    "    states = np.array([each[0] for each in batch])\n",
    "    actions = np.array([each[1] for each in batch])\n",
    "    rewards = np.array([each[2] for each in batch])\n",
    "    next_states = np.array([each[3] for each in batch])\n",
    "    \n",
    "    agent.learn(states,  actions, rewards, next_states, done, batch_size, verbose = 1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18fd0bb0ac8>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = np.arange(num_episodes)\n",
    "smoothed_rews = running_mean(score_history, 10)\n",
    "plt.plot(episodes[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(episodes, score_history,color='grey', alpha=0.3)\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.legend([\"avg reward\", \"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action LK: 2, action split: [0.5], reward: -0.12775379014095772\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n",
      "action LK: 2, action split: [0.5], reward: -100\n"
     ]
    }
   ],
   "source": [
    "#test agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    state = state[np.newaxis, :]\n",
    "    action_discrete, action_continuous = agent.policy.predict(state)\n",
    "    action_discrete = np.argmax(action_discrete)\n",
    "    action = action_discrete, action_continuous\n",
    "    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f'action LK: {action_discrete}, action split: {action_continuous[0]}, reward: {reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.1, 6.8, 9.1, 6.8, 6.8, 6.8]),\n",
       " array([9.1       , 6.8       , 4.55000019, 3.4000001 , 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 4.54999981, 3.3999999 , 6.8       ,\n",
       "        6.8       ]),\n",
       " array([9.1       , 6.8       , 2.2750001 , 1.70000005, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 2.2750001 , 1.70000005, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 2.27499986, 1.69999993, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 2.27499995, 1.69999998, 6.8       ,\n",
       "        6.8       ]),\n",
       " array([9.1       , 6.8       , 1.13750005, 0.85000002, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13750005, 0.85000002, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13750005, 0.85000002, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13750005, 0.85000002, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13749993, 0.84999996, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13749993, 0.84999996, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13749993, 0.84999996, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 1.13750002, 0.85000001, 6.8       ,\n",
       "        6.8       ]),\n",
       " array([9.1       , 6.8       , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ]),\n",
       " array([0.        , 0.        , 0.56875002, 0.42500001, 0.        ,\n",
       "        0.        ])]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.stream_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_discrete, action_continuous = agent.policy.predict(state[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('Agent.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
