{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from Distillation_disc_cont import simulator\n",
    "from Actor_Critic import Agent\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.load_session('Agent.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of Distillation_disc_cont failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\meatrobot\\Anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\meatrobot\\Anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"C:\\Users\\meatrobot\\Anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"C:\\Users\\meatrobot\\Anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"C:\\Users\\meatrobot\\Anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 280, in update_instances\n",
      "    frame = next(frame_nfo.frame for frame_nfo in inspect.stack()\n",
      "StopIteration\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 20)           140         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 20)           420         fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 20)           420         fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "policy_output (Dense)           (None, 1)            21          fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "discrete_action_output (Dense)  (None, 5)            105         fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "policy_output_actual_value (Lam (None, 1)            0           policy_output[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,106\n",
      "Trainable params: 1,106\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = simulator()\n",
    "agent = Agent(env = env, alpha = 1e-6, beta = 1e-7, gamma = 0.99)\n",
    "agent.actor.summary()\n",
    "#agent.critic.summary()\n",
    "#agent.policy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Github\\RL-Process-Design\\Discrete and Continuous\\Distillation_disc_cont.py:64: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  LK_B = bots[Light_Key]/sum(bots)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, avg_score -20044.326273422193, last action (3, array([[0.9457034]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Github\\RL-Process-Design\\Discrete and Continuous\\Distillation_disc_cont.py:74: RuntimeWarning: invalid value encountered in log\n",
      "  N =  np.log(LK_D/(1-LK_D) * (1-LK_B)/LK_B)/np.log(self.relative_volatility[Light_Key])\n",
      "D:\\Github\\RL-Process-Design\\Discrete and Continuous\\Distillation_disc_cont.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  LK_D = tops[Light_Key]/sum(tops)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 100, avg_score -17631.8131412606, last action (3, array([[0.30667746]]))\n",
      "episode 200, avg_score -16639.251991015106, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 300, avg_score -13189.882601523861, last action (3, array([[0.66011442]]))\n",
      "episode 400, avg_score -12095.150431569893, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 500, avg_score -11094.858020070535, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 600, avg_score -10894.834000597675, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 700, avg_score -8999.264342402566, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 800, avg_score -9316.786259701927, last action (2, array([[0.39506849]]))\n",
      "episode 900, avg_score -10274.003607900097, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 1000, avg_score -11386.329135626023, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 1100, avg_score -10416.644419876842, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 1200, avg_score -10103.206067747946, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 1300, avg_score -10688.190679681578, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 1400, avg_score -11258.656810804867, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 1500, avg_score -9603.777182480151, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 1600, avg_score -11462.64424417842, last action (1, array([[0.47057687]]))\n",
      "episode 1700, avg_score -11410.134626346848, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 1800, avg_score -10458.91454583875, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 1900, avg_score -10948.278005982631, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 2000, avg_score -10825.135239766376, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 2100, avg_score -10029.346468553571, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 2200, avg_score -10432.732069804617, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 2300, avg_score -11727.618646114672, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 2400, avg_score -10825.162031880049, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 2500, avg_score -9632.66587071215, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 2600, avg_score -8096.537953823708, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 2700, avg_score -8443.459970886375, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 2800, avg_score -8381.443968524307, last action (3, array([[-0.14604315]]))\n",
      "episode 2900, avg_score -7670.230780113991, last action (0, array([[0.77981784]]))\n",
      "episode 3000, avg_score -8919.498585395477, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 3100, avg_score -8136.965747113763, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 3200, avg_score -8742.662852657479, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 3300, avg_score -8847.542445377629, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 3400, avg_score -9583.371809834143, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 3500, avg_score -8409.769181692307, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 3600, avg_score -9240.043065713482, last action (0, array([[-0.89095514]]))\n",
      "episode 3700, avg_score -10597.070815683279, last action (4, array([[0.42365482]]))\n",
      "episode 3800, avg_score -10221.359326144655, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 3900, avg_score -10113.657207804872, last action (1, array([[0.3234625]]))\n",
      "episode 4000, avg_score -9510.99233770255, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 4100, avg_score -9147.450717302794, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 4200, avg_score -9847.659806963911, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 4300, avg_score -9745.74583166466, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 4400, avg_score -9695.38503201843, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 4500, avg_score -9477.677333878693, last action (2, array([[0.58261393]]))\n",
      "episode 4600, avg_score -9297.336561383985, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 4700, avg_score -10394.10064595779, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 4800, avg_score -10121.127207924214, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 4900, avg_score -8075.1401041184345, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 5000, avg_score -6845.963068697789, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 5100, avg_score -7972.025650630281, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 5200, avg_score -7381.987077590404, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 5300, avg_score -7091.158314234443, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 5400, avg_score -7000.658373909238, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 5500, avg_score -6432.8954929551, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 5600, avg_score -7080.997349902203, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 5700, avg_score -6771.794095022407, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 5800, avg_score -7706.626582795431, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 5900, avg_score -6905.885105106169, last action (1, array([[0.75886128]]))\n",
      "episode 6000, avg_score -6332.260142087258, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 6100, avg_score -7632.075146069963, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 6200, avg_score -6687.389583444255, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 6300, avg_score -7158.022616266607, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 6400, avg_score -7488.6034075294865, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 6500, avg_score -6680.03137323687, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 6600, avg_score -7427.784150814862, last action (4, array([[0.98221862]]))\n",
      "episode 6700, avg_score -6452.13091052221, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 6800, avg_score -7667.826957028131, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 6900, avg_score -8230.058867175261, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 7000, avg_score -8057.450229904224, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7100, avg_score -8248.901460957013, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 7200, avg_score -8438.19119948943, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7300, avg_score -8979.076220938114, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7400, avg_score -8251.835776450182, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7500, avg_score -8112.123055468433, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7600, avg_score -8597.0615512965, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7700, avg_score -8470.537423056134, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 7800, avg_score -8427.419701772604, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 7900, avg_score -8589.976867905725, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 8000, avg_score -8543.457583724005, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 8100, avg_score -8124.130798758158, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 8200, avg_score -7967.884062231301, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 8300, avg_score -8577.93401383628, last action (3, array([[0.93597487]]))\n",
      "episode 8400, avg_score -8914.17880497153, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 8500, avg_score -8195.308091570092, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 8600, avg_score -8670.155776798081, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 8700, avg_score -8072.754851388306, last action (2, array([[0.999]], dtype=float32))\n",
      "episode 8800, avg_score -8839.330588650884, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 8900, avg_score -9428.607542549167, last action (4, array([[0.999]], dtype=float32))\n",
      "episode 9000, avg_score -8941.643995066142, last action (2, array([[0.999]], dtype=float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9100, avg_score -8146.48697937499, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 9200, avg_score -8989.199088643834, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 9300, avg_score -9136.309702816705, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 9400, avg_score -9320.990669509132, last action (0, array([[0.999]], dtype=float32))\n",
      "episode 9500, avg_score -8942.731234772986, last action (4, array([[0.99854482]]))\n",
      "episode 9600, avg_score -8190.726942785722, last action (1, array([[0.999]], dtype=float32))\n",
      "episode 9700, avg_score -10085.90729916713, last action (3, array([[0.999]], dtype=float32))\n",
      "episode 9800, avg_score -9136.81748560058, last action (3, array([[0.999]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "score_history = []\n",
    "num_episodes = int(1e4)\n",
    "for i in range(num_episodes):\n",
    "\tdone = False\n",
    "\t\n",
    "\tstate = env.reset()\n",
    "\tscore = 0\n",
    "\t\n",
    "\twhile not done:\n",
    "\t\taction = agent.choose_action_epsgreedy(state, i, num_episodes)\n",
    "\t\tnext_state, reward, done, info = env.step(action)\n",
    "\t\tagent.learn(state,  action, reward, next_state, done)\n",
    "\t\tstate = next_state\n",
    "\t\tscore += reward\n",
    "\t\n",
    "\tscore_history.append(score)\n",
    "\tavg_score = np.mean(score_history[-100:]) #average of last 100 scores\n",
    "\tif i%100 == 0:\n",
    "\t\tprint(f'episode {i}, avg_score {avg_score}, last action {action}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = np.arange(num_episodes)\n",
    "smoothed_rews = running_mean(score_history, 10)\n",
    "plt.plot(episodes[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(episodes, score_history,color='grey', alpha=0.3)\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.legend([\"avg reward\", \"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while done == False:\n",
    "    state = state[np.newaxis, :]\n",
    "    action_discrete, action_continuous = agent.policy.predict(state)\n",
    "    action_discrete = np.argmax(action_discrete)\n",
    "    action = action_discrete, action_continuous\n",
    "    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f'action LK: {action_discrete}, action split: {action_continuous[0]}, reward: {reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.stream_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_discrete, action_continuous = agent.policy.predict(state[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('Agent.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
